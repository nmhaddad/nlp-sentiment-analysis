{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qE6Dme3N0Cb-"
   },
   "source": [
    "# Machine Learning Sentiment Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Classifying Wikipedia Comments\n",
    "\n",
    "\n",
    "Nathaniel Haddad - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9PFYC000CcJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import nltk\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ec-rw6Jr0CcY"
   },
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHo3yXZV0CcR"
   },
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I9OpSaP_zvAe"
   },
   "source": [
    "Normal File Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKmJnvmz0Cca"
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxvYdDxT0Ccg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEx91J_80Ccn"
   },
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annoatators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQZ5C6RQ0Cct"
   },
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N6tssOCo0Ccy"
   },
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vl43L3vCjlFa"
   },
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdFFfvNvrPHP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108333063</th>\n",
       "      <td>:My response: Wikipedia:Suspected sock puppet...</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48533215</th>\n",
       "      <td>== Rusty Harding ==  The last version before...</td>\n",
       "      <td>2006</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37004221</th>\n",
       "      <td>I removed NOTHING from the Poincare page  or...</td>\n",
       "      <td>2006</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395701986</th>\n",
       "      <td>` ::Fetchcomms has stated that you should gain...</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80463997</th>\n",
       "      <td>== List moved from article due to disputed n...</td>\n",
       "      <td>2006</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     comment  year  logged_in  \\\n",
       "rev_id                                                                          \n",
       "108333063   :My response: Wikipedia:Suspected sock puppet...  2007       True   \n",
       "48533215     == Rusty Harding ==  The last version before...  2006       True   \n",
       "37004221     I removed NOTHING from the Poincare page  or...  2006      False   \n",
       "395701986  ` ::Fetchcomms has stated that you should gain...  2010       True   \n",
       "80463997     == List moved from article due to disputed n...  2006       True   \n",
       "\n",
       "                ns   sample  split  attack  \n",
       "rev_id                                      \n",
       "108333063     user  blocked  train   False  \n",
       "48533215      user   random  train   False  \n",
       "37004221   article   random  train   False  \n",
       "395701986     user   random  train   False  \n",
       "80463997   article   random  train   False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zc2W5xPNLMUB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nathanielhaddad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxcMi3dl7fGa"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: parse_text\n",
    "param(s): text, a string\n",
    "returns: a string\n",
    "\"\"\"\n",
    "def parse_text(text):\n",
    "  new_text = []\n",
    "  # split text into list of items\n",
    "  words_and_symbols = str(text).split()\n",
    "  # iterate through each item and create a new string of alphabet characters\n",
    "  for item in words_and_symbols:\n",
    "    # make item lower case\n",
    "    item = item.lower()\n",
    "    # remove non-alpha characters and stopwords\n",
    "    if item.isalpha() and item not in STOPWORDS:\n",
    "        new_text.append(word)\n",
    "  return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEAzHNQ7B7_6"
   },
   "outputs": [],
   "source": [
    "# After testing text cleaning results above, no need to use this\n",
    "# comments[\"comment\"] = comments[\"comment\"].apply(parse_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpdlQFrp0Cc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "801279             Iraq is not good  ===  ===  USA is bad   \n",
       "2702703      ____ fuck off you little asshole. If you wan...\n",
       "4632658         i have a dick, its bigger than yours! hahaha\n",
       "6545332      == renault ==  you sad little bpy for drivin...\n",
       "6545351      == renault ==  you sad little bo for driving...\n",
       "7977970    34, 30 Nov 2004 (UTC)  ::Because you like to a...\n",
       "8359431    `  ::You are not worth the effort. You are arg...\n",
       "8724028    Yes, complain to your rabbi and then go shoot ...\n",
       "8845700                     i am using the sandbox, ass wipe\n",
       "8845736      == GOD DAMN ==  GOD DAMN it fuckers, i am us...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.query('attack')['comment'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5q03GMuhy-EG"
   },
   "source": [
    "## Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqDAHFb2YqsA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: build_confusion_matrix\n",
    "params: model, a function\n",
    "returns: nothing\n",
    "does: builds and prints a confusion matrix\n",
    "\"\"\"\n",
    "def build_confusion_matrix(model, y_pred):\n",
    "  cm = confusion_matrix(y_pred, test_comments['attack'])\n",
    "  print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95HYxdJmcTwX"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: precision_recall_fscore\n",
    "params: clf, a function\n",
    "returns: nothing\n",
    "does: calculates precision, recall, and f-score of given function\n",
    "\"\"\"\n",
    "def precision_recall_fscore(clf, y_pred):\n",
    "  metrics = precision_recall_fscore_support(\n",
    "      y_true=test_comments['attack'], y_pred=y_pred,\n",
    "      average='weighted')\n",
    "  print('Test Precision: %.5f' %metrics[0])\n",
    "  print('Test Recall: %.5f' %metrics[1])\n",
    "  print('Test F-Score: : %.5f' %metrics[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_8bF7qm0vJJ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: get_metrics\n",
    "params: clf, a function\n",
    "returns: nothing\n",
    "does: prints out confusion matrix, precision, recall, f-score, and ROC AUC\n",
    "\"\"\"\n",
    "def get_metrics(clf):\n",
    "  y_pred = clf.predict(test_comments['comment'])\n",
    "  build_confusion_matrix(clf, y_pred)\n",
    "  precision_recall_fscore(clf, y_pred)\n",
    "  auc = roc_auc_score(test_comments['attack'], clf.predict_proba(test_comments['comment'])[:,1])\n",
    "  print('Test ROC AUC: %.5f' %auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0eHjLAozGsx"
   },
   "source": [
    "## Models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sd1bChpct9rc"
   },
   "source": [
    "### Logistic Regression (strawman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnbBM6ra0Cc-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20280  1236]\n",
      " [  142  1520]]\n",
      "Test Precision: 0.93923\n",
      "Test Recall: 0.94055\n",
      "Test F-Score: : 0.93396\n",
      "Test ROC AUC: 0.95699\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', LogisticRegression(solver='lbfgs')),\n",
    "])\n",
    "\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJhzfjPV00MA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2cdyGD_1Hfq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/lr_base_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OCOKINlCbpa3"
   },
   "source": [
    "### Logistic Regression (\\#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYn-oz1dzWxt"
   },
   "outputs": [],
   "source": [
    "# create a new training set made up of validation set and previous training set\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "val_comments = comments.query(\"split=='dev'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "train_comments = pd.concat([val_comments, train_comments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XufJAIPGZwZp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20270  1194]\n",
      " [  152  1562]]\n",
      "Test Precision: 0.94044\n",
      "Test Recall: 0.94193\n",
      "Test F-Score: : 0.93588\n",
      "Test ROC AUC: 0.96020\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    # replace CountVectorizer with TfidfVectorizer\n",
    "    ('vect', TfidfVectorizer(max_df=1.0, min_df=1, max_features=None, norm = 'l2')),\n",
    "    ('clf', LogisticRegression(solver='lbfgs')),\n",
    "])\n",
    "\n",
    "parameters = {'vect__analyzer': ('word', 'char', 'char_wb'),\n",
    "              'vect__ngram_range': [(1,1), (1,2)]}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, cv=3, n_jobs=-1)\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQlj45810zdm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oEtj8_x1Fhm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/lr_2_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyWwx_NVhul2"
   },
   "source": [
    "### Logisitic Regression (\\#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RbsbRldRtAVX"
   },
   "outputs": [],
   "source": [
    "# create feature union of character and word TFIDF vectorizers\n",
    "vectorizerW = TfidfVectorizer(lowercase=True, analyzer='word', stop_words=None, ngram_range = (1,1), max_df=1.0, min_df=1, max_features=None, norm = 'l2')\n",
    "vectorizerC = TfidfVectorizer(lowercase=True, analyzer='char', stop_words=None, ngram_range = (1,1), max_df=1.0, min_df=1, max_features=None, norm = 'l2')\n",
    "combined_features = FeatureUnion([('word', vectorizerW), ('char', vectorizerC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnX6v8togglW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20262  1153]\n",
      " [  160  1603]]\n",
      "Test Precision: 0.94177\n",
      "Test Recall: 0.94335\n",
      "Test F-Score: : 0.93780\n",
      "Test ROC AUC: 0.96259\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', LogisticRegression(n_jobs=-1)),\n",
    "])\n",
    "\n",
    "parameters = {'clf__solver': ('newton-cg', 'lbfgs')}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, cv=3, n_jobs=-1)\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqVsRlyK0yIC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lm6g-h0j1E5_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/lr_3_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FbzikbPb52a"
   },
   "source": [
    "### Logistic Regression (\\#4)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "zs1vp-Lftw4_",
    "outputId": "82f6c179-0eb4-4498-9ca6-96e2303c1e21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20248  1095]\n",
      " [  174  1661]]\n",
      "Test Precision: 0.94352\n",
      "Test Recall: 0.94525\n",
      "Test F-Score: : 0.94036\n",
      "Test ROC AUC: 0.96411\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', LogisticRegressionCV(cv=3,max_iter=100, solver='lbfgs', random_state=12345)),\n",
    "])\n",
    "\n",
    "parameters = {'clf__fit_intercept': (True, False),\n",
    "              'clf__refit': (True, False)}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, cv=3, n_jobs=-1)\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eg5rbAYi0xUV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQCNtopA1ETe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/lr_4_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1gsdEJsYbqC"
   },
   "source": [
    "### Multi-Layer Perceptron\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "LQvyv_snT6Vw",
    "outputId": "75dde811-7103-4cd2-98bd-0677c66ae19c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.23772074\n",
      "Validation score: 0.937588\n",
      "Iteration 2, loss = 0.12249908\n",
      "Validation score: 0.942658\n",
      "Iteration 3, loss = 0.08261204\n",
      "Validation score: 0.942173\n",
      "Iteration 4, loss = 0.06003344\n",
      "Validation score: 0.941472\n",
      "Iteration 5, loss = 0.04581809\n",
      "Validation score: 0.938990\n",
      "Iteration 6, loss = 0.03649753\n",
      "Validation score: 0.937318\n",
      "Iteration 7, loss = 0.03010518\n",
      "Validation score: 0.935861\n",
      "Iteration 8, loss = 0.02558240\n",
      "Validation score: 0.935538\n",
      "Iteration 9, loss = 0.02213808\n",
      "Validation score: 0.932247\n",
      "Iteration 10, loss = 0.01996782\n",
      "Validation score: 0.932571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanielhaddad/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20180  1090]\n",
      " [  242  1666]]\n",
      "Test Precision: 0.93977\n",
      "Test Recall: 0.94253\n",
      "Test F-Score: : 0.93789\n",
      "Test ROC AUC: 0.95430\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', MLPClassifier(hidden_layer_sizes=(150), max_iter=50, \n",
    "                          activation='relu', random_state=12345, \n",
    "                          validation_fraction=0.2, verbose=True, early_stopping=True)),\n",
    "])\n",
    "\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zXZ_NPd0wwZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Zk8MaYz1DlQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/mlp_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9eB1ISBBMk_"
   },
   "source": [
    "### Bernoulli Naive Bayes\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXCwYgzcAsZc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16522   822]\n",
      " [ 3900  1934]]\n",
      "Test Precision: 0.87875\n",
      "Test Recall: 0.79627\n",
      "Test F-Score: : 0.82447\n",
      "Test ROC AUC: 0.83327\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', BernoulliNB()),\n",
    "])\n",
    "\n",
    "parameters = {'clf__alpha': (0.2,0.4,0.6,0.8,1)}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, cv=3)\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afgU0hcL0uCU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42sf5KkB086Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/nb_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGNw1y4t0F1-"
   },
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2fLkqbIBQl6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20398  1968]\n",
      " [   24   788]]\n",
      "Test Precision: 0.91896\n",
      "Test Recall: 0.91406\n",
      "Test F-Score: : 0.89260\n",
      "Test ROC AUC: 0.93215\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', RandomForestClassifier(n_estimators=50)),\n",
    "])\n",
    "\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bmp7jaEN0CdC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2xzvhLJ0CdI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/forest_model.pkl')\n",
    "print('Model Saved')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "nathaniel_haddad_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
