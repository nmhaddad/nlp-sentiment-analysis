{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "collected-average",
   "metadata": {},
   "source": [
    "# Understanding User Comments via Sentiment Analysis\n",
    "\n",
    "---\n",
    "*TensorFlow*\n",
    "\n",
    "Nathaniel Haddad - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-assurance",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_LSTM():\n",
    "    return tf.keras.Sequential([\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=len(encoder.get_vocabulary()),\n",
    "            output_dim=64,\n",
    "            # Use masking to handle the variable sequence lengths\n",
    "            mask_zero=True),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_graphs(history, 'accuracy')\n",
    "    plt.ylim(None,1)\n",
    "    plt.subplot(1,2,2)\n",
    "    plot_graphs(history, 'loss')\n",
    "    plt.ylim(0,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url: str, fname: str) -> None:\n",
    "    \"\"\"\n",
    "    function: download_file\n",
    "    param(s): url (str): url to files; fname (str): the filename\n",
    "    returns: nothing\n",
    "    does: downloads files to local directory\n",
    "    \"\"\"\n",
    "    urllib.request.urlretrieve(url, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    \"\"\"\n",
    "    from tensorflow docs\n",
    "    \"\"\"\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-bottom",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637'\n",
    "\n",
    "download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-cincinnati",
   "metadata": {},
   "source": [
    "Create pandas dataframes for quick data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annoatators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-ordinary",
   "metadata": {},
   "source": [
    "Convert pandas dataframe to TensorFlow tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = comments.query(\"split=='train'\")\n",
    "test_data = comments.query(\"split=='test'\")\n",
    "\n",
    "train_labels = train_data.pop('attack')\n",
    "test_labels = test_data.pop('attack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data['comment'].values, train_labels.values))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data['comment'].values, test_labels.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-reserve",
   "metadata": {},
   "source": [
    "Get an example feature and label from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example, label in train_dataset.take(3):\n",
    "    print('text: {}\\n'.format(example.numpy()))\n",
    "    print('label: {}'.format(label.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-technician",
   "metadata": {},
   "source": [
    "Shuffle training and test datasets by specidied buffer and batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example, label in train_dataset.take(3):\n",
    "    print('texts: {}\\n'.format(example.numpy()[:3]))\n",
    "    print('labels: {}'.format(label.numpy()[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-brown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-singapore",
   "metadata": {},
   "source": [
    "After text vectorization, get vocabulary returns most frequent vocabulary (including padding and unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-feeling",
   "metadata": {},
   "source": [
    "Create indices for the tensors (zero-padded based on longest length of sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(3):\n",
    "    print(\"Original: {}\".format(example[n].numpy()))\n",
    "    print(\"Round-trip: {}\\n\".format(\" \".join(vocab[encoded_example[n]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-aging",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model_LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a sample text without padding.\n",
    "sample_text = ('What a great addition to Wikipedia '\n",
    "               'thanks so much for your contribution.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a sample text with padding\n",
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=5,\n",
    "                    validation_data=test_dataset, \n",
    "                    validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-responsibility",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-somerset",
   "metadata": {},
   "source": [
    "## Test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ('This is a good comment. Great job!')\n",
    "predictions = model.predict(np.array([sample_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ('This is a bad comment. You are a terrible person!'\n",
    "              'No one should ever have to read your stupid ideas!')\n",
    "predictions = model.predict(np.array([sample_text]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
