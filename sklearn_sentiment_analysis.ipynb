{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qE6Dme3N0Cb-"
   },
   "source": [
    "# Understanding User Comments via Sentiment Analysis\n",
    "\n",
    "---\n",
    "\n",
    "*Scikit-Learn*\n",
    "\n",
    "Nathaniel Haddad - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9PFYC000CcJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import nltk\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url: str, fname: str) -> None:\n",
    "    \"\"\"\n",
    "    function: download_file\n",
    "    param(s): url (str): url to files; fname (str): the filename\n",
    "    returns: nothing\n",
    "    does: downloads files to local directory\n",
    "    \"\"\"\n",
    "    urllib.request.urlretrieve(url, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxcMi3dl7fGa"
   },
   "outputs": [],
   "source": [
    "def parse_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    function: parse_text\n",
    "    param(s): text, a string\n",
    "    returns: a string\n",
    "    \"\"\"\n",
    "    new_text = []\n",
    "    # split text into list of items\n",
    "    words_and_symbols = str(text).split()\n",
    "    # iterate through each item and create a new string of alphabet characters\n",
    "    for item in words_and_symbols:\n",
    "    # make item lower case\n",
    "    item = item.lower()\n",
    "    # remove non-alpha characters and stopwords\n",
    "    if item.isalpha() and item not in STOPWORDS:\n",
    "        new_text.append(word)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqDAHFb2YqsA"
   },
   "outputs": [],
   "source": [
    "def build_confusion_matrix(model, y_pred) -> None:\n",
    "    \"\"\"\n",
    "    function: build_confusion_matrix\n",
    "    params: model, a function\n",
    "    returns: nothing\n",
    "    does: builds and prints a confusion matrix\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_pred, test_comments['attack'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95HYxdJmcTwX"
   },
   "outputs": [],
   "source": [
    "def precision_recall_fscore(clf, y_pred) -> None:\n",
    "    \"\"\"\n",
    "    function: precision_recall_fscore\n",
    "    params: clf, a function\n",
    "    returns: nothing\n",
    "    does: calculates precision, recall, and f-score of given function\n",
    "    \"\"\"\n",
    "    metrics = precision_recall_fscore_support(\n",
    "      y_true = test_comments['attack'], y_pred = y_pred, average = 'weighted')\n",
    "    print('Test Precision: {precision:.5f}'.format(precision = metrics[0]))\n",
    "    print('Test Recall: {recall:.5f}'.format(recall = metrics[1]))\n",
    "    print('Test F-Score: : {fscore:.5f}'.format(fscore = metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_8bF7qm0vJJ"
   },
   "outputs": [],
   "source": [
    "def get_metrics(clf) -> None:\n",
    "    \"\"\"\n",
    "    function: get_metrics\n",
    "    params: clf, a function\n",
    "    returns: nothing\n",
    "    does: prints out confusion matrix, precision, recall, f-score, and ROC AUC\n",
    "    \"\"\"\n",
    "    y_pred = clf.predict(test_comments['comment'])\n",
    "    build_confusion_matrix(clf, y_pred)\n",
    "    precision_recall_fscore(clf, y_pred)\n",
    "    auc = roc_auc_score(test_comments['attack'], clf.predict_proba(test_comments['comment'])[:,1])\n",
    "    print('Test ROC AUC: {aucscore:.5f}'.format(aucscore = auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ec-rw6Jr0CcY"
   },
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHo3yXZV0CcR"
   },
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637'\n",
    "\n",
    "download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKmJnvmz0Cca"
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxvYdDxT0Ccg"
   },
   "outputs": [],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEx91J_80Ccn"
   },
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annoatators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQZ5C6RQ0Cct"
   },
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N6tssOCo0Ccy"
   },
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vl43L3vCjlFa"
   },
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdFFfvNvrPHP"
   },
   "outputs": [],
   "source": [
    "comments.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zc2W5xPNLMUB"
   },
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEAzHNQ7B7_6"
   },
   "outputs": [],
   "source": [
    "# After testing text cleaning results above, no need to use this\n",
    "# comments[\"comment\"] = comments[\"comment\"].apply(parse_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpdlQFrp0Cc3"
   },
   "outputs": [],
   "source": [
    "# comments.query('attack')['comment'].head(10) # uncomment this to read some horrible stuff :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0eHjLAozGsx"
   },
   "source": [
    "## Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sd1bChpct9rc"
   },
   "source": [
    "### Logistic Regression (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnbBM6ra0Cc-"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', LogisticRegression(solver ='lbfgs')),\n",
    "])\n",
    "\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJhzfjPV00MA"
   },
   "outputs": [],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2cdyGD_1Hfq"
   },
   "outputs": [],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/lr_base_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OCOKINlCbpa3"
   },
   "source": [
    "### Logistic Regression (\\#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYn-oz1dzWxt"
   },
   "outputs": [],
   "source": [
    "# create a new training set made up of validation set and previous training set\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "val_comments = comments.query(\"split=='dev'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "train_comments = pd.concat([val_comments, train_comments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XufJAIPGZwZp"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    # replace CountVectorizer with TfidfVectorizer\n",
    "    ('vect', TfidfVectorizer(max_df=1.0, min_df=1, max_features=None, norm = 'l2')),\n",
    "    ('clf', LogisticRegression(solver='lbfgs')),\n",
    "])\n",
    "\n",
    "parameters = {'vect__analyzer': ('word', 'char', 'char_wb'),\n",
    "              'vect__ngram_range': [(1,1), (1,2)]}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, cv = 3, n_jobs = -1)\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQlj45810zdm"
   },
   "outputs": [],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oEtj8_x1Fhm"
   },
   "outputs": [],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/lr_2_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyWwx_NVhul2"
   },
   "source": [
    "### Logisitic Regression (\\#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RbsbRldRtAVX"
   },
   "outputs": [],
   "source": [
    "# create feature union of character and word TFIDF vectorizers\n",
    "vectorizerW = TfidfVectorizer(lowercase=True, analyzer='word', stop_words=None, ngram_range = (1,1), max_df=1.0, min_df=1, max_features=None, norm = 'l2')\n",
    "vectorizerC = TfidfVectorizer(lowercase=True, analyzer='char', stop_words=None, ngram_range = (1,1), max_df=1.0, min_df=1, max_features=None, norm = 'l2')\n",
    "combined_features = FeatureUnion([('word', vectorizerW), ('char', vectorizerC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnX6v8togglW"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', LogisticRegression(n_jobs=-1)),\n",
    "])\n",
    "\n",
    "parameters = {'clf__solver': ('newton-cg', 'lbfgs')}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, cv=3, n_jobs=-1)\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqVsRlyK0yIC"
   },
   "outputs": [],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lm6g-h0j1E5_"
   },
   "outputs": [],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/lr_3_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FbzikbPb52a"
   },
   "source": [
    "### Logistic Regression (\\#4)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "zs1vp-Lftw4_",
    "outputId": "82f6c179-0eb4-4498-9ca6-96e2303c1e21"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', LogisticRegressionCV(cv=3,max_iter=100, solver='lbfgs', random_state=12345)),\n",
    "])\n",
    "\n",
    "parameters = {'clf__fit_intercept': (True, False),\n",
    "              'clf__refit': (True, False)}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, cv=3, n_jobs=-1)\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eg5rbAYi0xUV"
   },
   "outputs": [],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQCNtopA1ETe"
   },
   "outputs": [],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/lr_4_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1gsdEJsYbqC"
   },
   "source": [
    "### Multi-Layer Perceptron\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "LQvyv_snT6Vw",
    "outputId": "75dde811-7103-4cd2-98bd-0677c66ae19c"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', MLPClassifier(hidden_layer_sizes=(150), max_iter=50, \n",
    "                          activation='relu', random_state=12345, \n",
    "                          validation_fraction=0.2, verbose=True, early_stopping=True)),\n",
    "])\n",
    "\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zXZ_NPd0wwZ"
   },
   "outputs": [],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Zk8MaYz1DlQ"
   },
   "outputs": [],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/mlp_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9eB1ISBBMk_"
   },
   "source": [
    "### Bernoulli Naive Bayes\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXCwYgzcAsZc"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', BernoulliNB()),\n",
    "])\n",
    "\n",
    "parameters = {'clf__alpha': (0.2,0.4,0.6,0.8,1)}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, cv=3)\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afgU0hcL0uCU"
   },
   "outputs": [],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42sf5KkB086Z"
   },
   "outputs": [],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/nb_model.pkl')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGNw1y4t0F1-"
   },
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2fLkqbIBQl6"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', RandomForestClassifier(n_estimators=50)),\n",
    "])\n",
    "\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "get_metrics(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bmp7jaEN0CdC"
   },
   "outputs": [],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2xzvhLJ0CdI"
   },
   "outputs": [],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "joblib.dump(clf, 'models/forest_model.pkl')\n",
    "print('Model Saved')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "nathaniel_haddad_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
